{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junseon00/Pytorch-Study/blob/main/ai504_03_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0tYW572drhv"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1vC0N3Obk4HZJk9JOG7fKgYE10YYlCqsg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n6CfTv3drhy"
      },
      "source": [
        "# Week 3: PyTorch, Logistic Regression and MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FijO3OAYdrhz"
      },
      "source": [
        "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
        "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
        "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpzGwsNqdrh0"
      },
      "source": [
        "## Why PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KnhRG1Mdrh0"
      },
      "source": [
        "- Intuitive and concise code\n",
        "- Define by Run method (Tensorflow is Define and Run method)\n",
        "- High compatibility with Numpy (almost one-to-one mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHrsM4Jadrh0"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBpgWBONdrh1"
      },
      "source": [
        "## 0. Prelim: Load packages & GPU setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYOS31Rcdrh1",
        "outputId": "33f36da3-7faf-4354-b408-ff19ed8e30e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 05:14:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# visualize current GPU usages in your server\n",
        "!nvidia-smi "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp8sNERNdrh3"
      },
      "outputs": [],
      "source": [
        "# set gpu by number \n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyaE_fC7drh4"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2t15SEbdrh4",
        "outputId": "6b078070-1785-44bc-bda8-73b6ed3d3f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "# print the version of PyTorch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8gyntP0drh5"
      },
      "source": [
        "## 1. PyTorch and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwK4npWwdrh5"
      },
      "source": [
        "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
        "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
        "**Almost the same with Numpy array**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1oLWixkdrh5"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk-8r9P9drh6"
      },
      "source": [
        "### PyTorch and Numpy shares almost identical grammer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drMC0w1udrh6"
      },
      "source": [
        "\n",
        "**We will show some examples of:**\n",
        "- Same operation with identical grammer\n",
        "- Same operation with different grammer\n",
        "- Different operation with same grammer\n",
        "\n",
        "**We will not handle all examples in this class :(**\n",
        "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2S_51tbdrh6"
      },
      "source": [
        "**First! Define Numpy array and PyTorch tensor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgiW8f8Vdrh6",
        "outputId": "2b2b1188-4258-450f-af59-d38bb7020dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4]\n",
            "[5 6 7 8]\n",
            "tensor([1, 2, 3, 4])\n",
            "tensor([5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "np_array_1 = np.array([1, 2, 3, 4])\n",
        "np_array_2 = np.array([5, 6, 7, 8])\n",
        "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
        "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
        "\n",
        "print (np_array_1)\n",
        "print (np_array_2)\n",
        "print (torch_tensor_1)\n",
        "print (torch_tensor_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxmTNPAYdrh7"
      },
      "source": [
        "**1) Same operations with identical grammer**\n",
        "\n",
        "Example) Get the shape of the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfruq5R6drh7",
        "outputId": "c5235ddb-4592-4f0f-c135-fc918cecf1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "print (np_array_1.shape)\n",
        "\n",
        "# torch\n",
        "print (torch_tensor_1.shape)\n",
        "print (torch_tensor_1.size()) # size() and shape operation is identical in torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH55IN7Pdrh7"
      },
      "source": [
        "**2) Same operations with different grammer**\n",
        "\n",
        "Example 1) Concatenate two tensors\n",
        "- numpy use `np.concatenate`\n",
        "- torch use `torch.cat`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEnrK1zxdrh7",
        "outputId": "6eb7b4fa-8258-4299-bb52-b945df12ff0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[1 2 3 4 5 6 7 8]\n",
            "----torch----\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n",
        "print ('----numpy----')\n",
        "print (np_concate)\n",
        "\n",
        "# torch\n",
        "torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
        "print ('----torch----')\n",
        "print (torch_concate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSm-5VKNdrh8"
      },
      "source": [
        "Example 2) reshape the tensor shape\n",
        "- numpy use `X.reshape`\n",
        "- torch use `X.view`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKxUI4lndrh8",
        "outputId": "79f46c1b-3ae7-4eca-ee0d-be271e55fd33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]]\n",
            "(4, 2)\n",
            "----torch----\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_reshaped = np_concate.reshape(4, 2)\n",
        "print ('----numpy----')\n",
        "print (np_reshaped)\n",
        "print (np_reshaped.shape)\n",
        "\n",
        "# torch\n",
        "torch_reshaped = torch_concate.view(4, 2)\n",
        "print ('----torch----')\n",
        "print (torch_reshaped)\n",
        "print (torch_reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDmdbl7drh8"
      },
      "source": [
        "**3) Different operations with same grammer (Confusing operations)**\n",
        "\n",
        "Example) manipulation tensors\n",
        "- Same grammer `repeat`  has different operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OnhpIW5drh8",
        "outputId": "a6e384cb-c0c2-4f30-be07-6c0ff0075dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----numpy----\n",
            "[1 2 3]\n",
            "[1 1 1 2 2 2 3 3 3]\n",
            "----torch----\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3, 1, 2, 3])\n",
            "tensor([1, 1, 2, 2, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3])\n",
        "x_repeat = x.repeat(3)\n",
        "\n",
        "print ('----numpy----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----torch----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
        "x_repeat = x.repeat_interleave(2)\n",
        "print (x_repeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1PGblK3drh9",
        "outputId": "2e7dc6b7-ccdc-4468-d226-602682b18447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n"
          ]
        }
      ],
      "source": [
        "# similar manipulation operation: stack & repeat\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(4)\n",
        "x_stack = torch.stack([x, x, x, x])\n",
        "\n",
        "print (x_repeat)\n",
        "print (x_stack)\n",
        "print (x_repeat.view(4, 3)) # reshape x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oObuqQydrh9"
      },
      "source": [
        "## 2. Tensor operations under GPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UDcwG2Wdrh9"
      },
      "source": [
        "Deep learning frameworks utilize GPUs to accelarate computations.\n",
        "\n",
        "In this section, we will learn **how to utilize GPU** in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlyBGNffdrh9",
        "outputId": "db609cb8-3495-4111-fd2b-7d8f60fe350b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())  # Is GPU accessible?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPBZydROdrh-"
      },
      "outputs": [],
      "source": [
        "a = torch.ones(3)\n",
        "b = torch.randn(100, 50, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYd_VrgRdrh-",
        "outputId": "7b69d329-a497-419a-f6d9-0488089af8d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOfwWLx2drh-"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqubXYTGdrh-",
        "outputId": "f724773a-23b1-4c1a-fd7d-a7e5abd16331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrMT156Ydrh-"
      },
      "outputs": [],
      "source": [
        "# upload a and b to GPU\n",
        "a = a.to('cuda')\n",
        "b = b.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfV6Jdbadrh_",
        "outputId": "b2b3b6ff-5386-44ae-81c4-971c8eab7e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBD3no1wdrh_"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Qr2geXdrh_",
        "outputId": "daa214c9-55ff-4161-88b1-e4ae4a49529b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDcarWk_drh_"
      },
      "outputs": [],
      "source": [
        "c = c.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf2anjuMdrh_",
        "outputId": "379e74ad-121d-4908-f236-47f67348a280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvEbxAf1drh_"
      },
      "source": [
        "## 3. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShYfVuzodrh_"
      },
      "source": [
        "Central to all neural networks in PyTorch is the `autograd` package. \n",
        "\n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzUJfis9driA"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpVG_xT5driA",
        "outputId": "b5f45142-9b16-4c1e-aaf0-26d76109e385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "#requires_grad : tensor 내의 element는 int가 아닌 float형이어야 함\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q4farG-driA",
        "outputId": "f75e0191-dedb-482d-90e7-a7d933c6163a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6aK7dmhdriA",
        "outputId": "a889d8fd-d13f-4bb2-a75d-9ee915847673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnd5C0NhdriA",
        "outputId": "8ae9e4b3-4dbc-44f4-8e99-5dab74cf69d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = z.mean()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cfk9KZ4udriA"
      },
      "outputs": [],
      "source": [
        "#retain_grad : 해당 변수에 대한 gradient 연산을 기억, 이거 안하면 중간 변수에 대한 gradient는 저장되지 않음 \n",
        "y.retain_grad()\n",
        "z.retain_grad()\n",
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TMMD8sLdriA"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n",
        "![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuoN5lZ2driB",
        "outputId": "a999b837-08ab-4285-8497-f85e7b739813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "print(z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgjiexeHdriB"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n",
        "![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uctwGLksdriB",
        "outputId": "f9fca490-45b1-40db-c107-dd03fe708322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "# retain_grad를 하지 않았다면,  z.grad / y.grad 시에  runtimeError\n",
        "print(y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmItugEcdriB"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n",
        "![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX6eE2mldriB",
        "outputId": "34d463a5-6f42-4353-e7aa-c3bebfc074b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efs0kibDdriB"
      },
      "source": [
        "### Efficient inference (testing) with torch.no_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf4p3LYidriB"
      },
      "source": [
        "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
        "\n",
        "Situation: when **gradient calculation is not required** e.g., inference\\\n",
        "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ypmUn7OdriC"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    x = torch.ones(2, 2, requires_grad=True)\n",
        "    y = x + 2\n",
        "    z = y * y * 3\n",
        "    out = z.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d-HqWaNdriC",
        "outputId": "24dc5ae1-ad7e-4bf9-a04d-7e3dcda561f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "hDidQCU0driC",
        "outputId": "414bde08-f180-4b20-afc7-de1ab0b5b553"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bf3332dd1f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## ERROR!!!!: we used torch.no_grad()!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkWd50WNdriC"
      },
      "source": [
        "## 4. nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdJ0qQ9GdriC"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reMTMllQdriC"
      },
      "source": [
        "### Using pre-defined modules (subset of models) in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNNCrEoMdriC",
        "outputId": "c505591b-4900-4d19-93f2-087ee3c69657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "\n",
        "print (X)\n",
        "print (X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSOMKXw_driC"
      },
      "outputs": [],
      "source": [
        "# input dim 3, output dim 1\n",
        "linear_fn = nn.Linear(3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkcrFPrBdriD",
        "outputId": "30253ea6-0477-4c5a-bdfd-069f8c797f66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=1, bias=True)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "linear_fn  # WX + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjtsfWLodriD",
        "outputId": "0641eb36-2912-4811-be3c-1c59c527eae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-2.0141],\n",
            "        [-4.8248]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ],
      "source": [
        "Y = linear_fn(X)\n",
        "print(Y)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ5rHCTcdriD",
        "outputId": "c0c5f3b0-a6bb-4eb2-e366-477ddbc02411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-6.8389, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "Y = Y.sum()\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o5RJq5OdriD"
      },
      "source": [
        "You can use other types of `nn.Module` in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JmyY5j9driD"
      },
      "outputs": [],
      "source": [
        "nn.Conv2d\n",
        "nn.RNNCell\n",
        "nn.LSTMCell\n",
        "nn.GRUCell\n",
        "nn.Transformer;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkwXRPbidriD"
      },
      "source": [
        "### How can we design a customized model (neural network)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sup37yPVdriD"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x) # Activation function\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5ctc26idriE"
      },
      "source": [
        "**What is activation function?**\n",
        "- They make non-linearity for deep neural networks\n",
        "- Therefore, deep neural networks can approximate complex functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIR3Dzu9driE"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1dxJJUOzYykRfW2q3my2Qtg82RsjptIx4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1k_fxS7driE"
      },
      "outputs": [],
      "source": [
        "nn.Sigmoid\n",
        "nn.ReLU\n",
        "nn.LeakyReLU\n",
        "nn.Tanh;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY8AFf6MdriE"
      },
      "source": [
        "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkpQS9_IdriE"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1kdig6RLSCvYJNqarbb8gviYsnxZfSkYQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX82GfH1driE"
      },
      "source": [
        "### What is MNIST & How to do multi-class classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds9TVlRjdriE"
      },
      "source": [
        "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
        "\n",
        "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUGUq4DKdriE"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn1NemM-driE"
      },
      "source": [
        "### Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC1TL2VcdriE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJorJLHzdriF"
      },
      "source": [
        "### Load datasets for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439,
          "referenced_widgets": [
            "82ce801b0f414818a2bca4d7afb9732e",
            "05dd84e745284ea184c841d4cb30a007",
            "6abe08b0c96b408baa62e48069072a3b",
            "9ce60f3174c54ea08bfb0be822532d17",
            "84934e21775b46f4a37a6eb13b3b0c0a",
            "1d3f358622934f85a1f65898b647a15d",
            "685437017e68411c8ba0661eefcd4d1a",
            "6ce6a72099b743219d98808fcb12410f",
            "77dbcb05a88e4e9bae01cf2ef6470fad",
            "039f1deb71dc4c1f98213adef7b49bb6",
            "1f6212f64f5c47859002e0783b7b03b6",
            "ae72f88799da41eaa1da11c235a44e56",
            "5f7b1a04bda84030b964ce1c7bf7550d",
            "defb7a8bf92f47709fb1a9607e7c0139",
            "05c4875a4cab4826bf0d42acdda53bd6",
            "016fa05d5c414eb4b27df99b3da01329",
            "9ed4bb406d7e4a5195d5fcaec2b63316",
            "d192558e10bb49d68627ca9d11d68fd9",
            "c52afe9ae4f14608b6a2931c501ad571",
            "a90f23e044384b4ca68765d24098b2e9",
            "f98ac5d3eb624ee9a7ebc46a45aba889",
            "fb677429e6b149a3a059b5d084ef818a",
            "7d2469f2b243420b97cba7712127992e",
            "71321d6189bd4572a64ff50443f5dee4",
            "3d51bf9fdde24aac87ac7194f14a4a8b",
            "a5a9dda8ba4440e4bec13a033013a95a",
            "dd1028be15d34724b90c19404cc03258",
            "d1df58c78c6a4f168668c2ab617308ef",
            "c2dcaaaac664435cb1c26b9903876d8b",
            "6d612224dd87475f9d2a94fa19d386bc",
            "4208e9b71e1e444da1a1afecd82af5bf",
            "3c1f0aed54f74da0ab0f15dd7a4e0624",
            "78720c06dba4447286ced65295ce0dc1",
            "2e664dea983249ac952444aadcf6f619",
            "0a6f267706c5477d9c3f5d244dc3cd75",
            "bc21eaefc907404db8af22af89d1b21d",
            "c0f03843f92c4bbbb194eb37efded800",
            "2b20154ce71445ab9fa99cd73b0e36fd",
            "6a9882d6f35a4547b8461005bf793fac",
            "40715c1505914e7a9ebaf57dd56a71b0",
            "067d6c9293f5449799d52a4b4583bb4e",
            "e5cdb3b11c514e49ad0bda92e1fea09a",
            "dda412cfec8349af90f21e543daa9dcf",
            "af3dd60447a74fa3a25770e6e298fe74"
          ]
        },
        "id": "ui2D82eYdriF",
        "outputId": "f42e37c3-9dcf-4f0a-af07-d584700186e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82ce801b0f414818a2bca4d7afb9732e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae72f88799da41eaa1da11c235a44e56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d2469f2b243420b97cba7712127992e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e664dea983249ac952444aadcf6f619",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "# mini batch size\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQmbIv1ZdriF"
      },
      "source": [
        "### Define model (we will use one layer classifier first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFlQs7aOdriF"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Xe4J88NglbuASnfYJYI7ISqA1c1rcs5P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0r8FhrRrdriF"
      },
      "outputs": [],
      "source": [
        "# Define model class\n",
        "# This model has one hidden layer\n",
        "class Multinomial_logistic_regression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Multinomial_logistic_regression, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY57fxtxdriF"
      },
      "outputs": [],
      "source": [
        "# Generate model\n",
        "model = Multinomial_logistic_regression(784, 10)  # init(784, 10)\n",
        "# input dim: 784  / output dim: 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVVQn8lSdriF",
        "outputId": "6945d603-15df-41ac-b561-396b1e4f39a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Multinomial_logistic_regression(\n",
              "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK6Sb0XFdriF"
      },
      "outputs": [],
      "source": [
        "# Upload model to GPU\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVQty5XzdriF"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGNOauS1driG"
      },
      "source": [
        "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
        "\n",
        "PyTorch optimizer is about **which optimization methods to use for training**\n",
        "\n",
        "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWEnKAdqdriG"
      },
      "outputs": [],
      "source": [
        "# Optimizer define\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbqtK15GdriG"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynbiBVtNdriG"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlqHlgzqdriG",
        "outputId": "5dc2f7cb-d45d-4fbb-d0ee-fa35a4aee1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.3389\n",
            "Epoch [1/10], Step [200/469], Loss: 0.2955\n",
            "Epoch [1/10], Step [300/469], Loss: 0.3021\n",
            "Epoch [1/10], Step [400/469], Loss: 0.1851\n",
            "Epoch [2/10], Step [100/469], Loss: 0.2745\n",
            "Epoch [2/10], Step [200/469], Loss: 0.2878\n",
            "Epoch [2/10], Step [300/469], Loss: 0.3074\n",
            "Epoch [2/10], Step [400/469], Loss: 0.2390\n",
            "Epoch [3/10], Step [100/469], Loss: 0.4346\n",
            "Epoch [3/10], Step [200/469], Loss: 0.2790\n",
            "Epoch [3/10], Step [300/469], Loss: 0.2630\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2951\n",
            "Epoch [4/10], Step [100/469], Loss: 0.3817\n",
            "Epoch [4/10], Step [200/469], Loss: 0.1869\n",
            "Epoch [4/10], Step [300/469], Loss: 0.3571\n",
            "Epoch [4/10], Step [400/469], Loss: 0.3357\n",
            "Epoch [5/10], Step [100/469], Loss: 0.3610\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2607\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1866\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2976\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2422\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2916\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2980\n",
            "Epoch [6/10], Step [400/469], Loss: 0.3435\n",
            "Epoch [7/10], Step [100/469], Loss: 0.2858\n",
            "Epoch [7/10], Step [200/469], Loss: 0.1387\n",
            "Epoch [7/10], Step [300/469], Loss: 0.2606\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2605\n",
            "Epoch [8/10], Step [100/469], Loss: 0.2143\n",
            "Epoch [8/10], Step [200/469], Loss: 0.1646\n",
            "Epoch [8/10], Step [300/469], Loss: 0.2473\n",
            "Epoch [8/10], Step [400/469], Loss: 0.3197\n",
            "Epoch [9/10], Step [100/469], Loss: 0.4069\n",
            "Epoch [9/10], Step [200/469], Loss: 0.2607\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1807\n",
            "Epoch [9/10], Step [400/469], Loss: 0.2288\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1890\n",
            "Epoch [10/10], Step [200/469], Loss: 0.3097\n",
            "Epoch [10/10], Step [300/469], Loss: 0.2515\n",
            "Epoch [10/10], Step [400/469], Loss: 0.2242\n",
            "Epoch [11/10], Step [100/469], Loss: 0.1776\n",
            "Epoch [11/10], Step [200/469], Loss: 0.1534\n",
            "Epoch [11/10], Step [300/469], Loss: 0.2309\n",
            "Epoch [11/10], Step [400/469], Loss: 0.3024\n",
            "Epoch [12/10], Step [100/469], Loss: 0.3260\n",
            "Epoch [12/10], Step [200/469], Loss: 0.3036\n",
            "Epoch [12/10], Step [300/469], Loss: 0.3637\n",
            "Epoch [12/10], Step [400/469], Loss: 0.1832\n",
            "Epoch [13/10], Step [100/469], Loss: 0.2330\n",
            "Epoch [13/10], Step [200/469], Loss: 0.3922\n",
            "Epoch [13/10], Step [300/469], Loss: 0.3329\n",
            "Epoch [13/10], Step [400/469], Loss: 0.2208\n",
            "Epoch [14/10], Step [100/469], Loss: 0.3527\n",
            "Epoch [14/10], Step [200/469], Loss: 0.3659\n",
            "Epoch [14/10], Step [300/469], Loss: 0.2135\n",
            "Epoch [14/10], Step [400/469], Loss: 0.2385\n",
            "Epoch [15/10], Step [100/469], Loss: 0.4475\n",
            "Epoch [15/10], Step [200/469], Loss: 0.1560\n",
            "Epoch [15/10], Step [300/469], Loss: 0.2204\n",
            "Epoch [15/10], Step [400/469], Loss: 0.1739\n",
            "Epoch [16/10], Step [100/469], Loss: 0.4321\n",
            "Epoch [16/10], Step [200/469], Loss: 0.3086\n",
            "Epoch [16/10], Step [300/469], Loss: 0.2157\n",
            "Epoch [16/10], Step [400/469], Loss: 0.2470\n",
            "Epoch [17/10], Step [100/469], Loss: 0.2376\n",
            "Epoch [17/10], Step [200/469], Loss: 0.1954\n",
            "Epoch [17/10], Step [300/469], Loss: 0.2464\n",
            "Epoch [17/10], Step [400/469], Loss: 0.2959\n",
            "Epoch [18/10], Step [100/469], Loss: 0.3455\n",
            "Epoch [18/10], Step [200/469], Loss: 0.2810\n",
            "Epoch [18/10], Step [300/469], Loss: 0.1568\n",
            "Epoch [18/10], Step [400/469], Loss: 0.1893\n",
            "Epoch [19/10], Step [100/469], Loss: 0.3106\n",
            "Epoch [19/10], Step [200/469], Loss: 0.1206\n",
            "Epoch [19/10], Step [300/469], Loss: 0.1490\n",
            "Epoch [19/10], Step [400/469], Loss: 0.1756\n",
            "Epoch [20/10], Step [100/469], Loss: 0.2967\n",
            "Epoch [20/10], Step [200/469], Loss: 0.2021\n",
            "Epoch [20/10], Step [300/469], Loss: 0.2909\n",
            "Epoch [20/10], Step [400/469], Loss: 0.2980\n",
            "Epoch [21/10], Step [100/469], Loss: 0.1996\n",
            "Epoch [21/10], Step [200/469], Loss: 0.1634\n",
            "Epoch [21/10], Step [300/469], Loss: 0.2665\n",
            "Epoch [21/10], Step [400/469], Loss: 0.4819\n",
            "Epoch [22/10], Step [100/469], Loss: 0.1403\n",
            "Epoch [22/10], Step [200/469], Loss: 0.2705\n",
            "Epoch [22/10], Step [300/469], Loss: 0.2274\n",
            "Epoch [22/10], Step [400/469], Loss: 0.2735\n",
            "Epoch [23/10], Step [100/469], Loss: 0.2989\n",
            "Epoch [23/10], Step [200/469], Loss: 0.2449\n",
            "Epoch [23/10], Step [300/469], Loss: 0.3134\n",
            "Epoch [23/10], Step [400/469], Loss: 0.1949\n",
            "Epoch [24/10], Step [100/469], Loss: 0.2580\n",
            "Epoch [24/10], Step [200/469], Loss: 0.2086\n",
            "Epoch [24/10], Step [300/469], Loss: 0.2287\n",
            "Epoch [24/10], Step [400/469], Loss: 0.3162\n",
            "Epoch [25/10], Step [100/469], Loss: 0.2368\n",
            "Epoch [25/10], Step [200/469], Loss: 0.5659\n",
            "Epoch [25/10], Step [300/469], Loss: 0.2065\n",
            "Epoch [25/10], Step [400/469], Loss: 0.1914\n",
            "Epoch [26/10], Step [100/469], Loss: 0.2779\n",
            "Epoch [26/10], Step [200/469], Loss: 0.2616\n",
            "Epoch [26/10], Step [300/469], Loss: 0.1735\n",
            "Epoch [26/10], Step [400/469], Loss: 0.2008\n",
            "Epoch [27/10], Step [100/469], Loss: 0.1694\n",
            "Epoch [27/10], Step [200/469], Loss: 0.2088\n",
            "Epoch [27/10], Step [300/469], Loss: 0.2760\n",
            "Epoch [27/10], Step [400/469], Loss: 0.2437\n",
            "Epoch [28/10], Step [100/469], Loss: 0.3942\n",
            "Epoch [28/10], Step [200/469], Loss: 0.4718\n",
            "Epoch [28/10], Step [300/469], Loss: 0.2266\n",
            "Epoch [28/10], Step [400/469], Loss: 0.1998\n",
            "Epoch [29/10], Step [100/469], Loss: 0.1866\n",
            "Epoch [29/10], Step [200/469], Loss: 0.1335\n",
            "Epoch [29/10], Step [300/469], Loss: 0.2181\n",
            "Epoch [29/10], Step [400/469], Loss: 0.1818\n",
            "Epoch [30/10], Step [100/469], Loss: 0.2488\n",
            "Epoch [30/10], Step [200/469], Loss: 0.2699\n",
            "Epoch [30/10], Step [300/469], Loss: 0.2863\n",
            "Epoch [30/10], Step [400/469], Loss: 0.3334\n",
            "Epoch [31/10], Step [100/469], Loss: 0.3948\n",
            "Epoch [31/10], Step [200/469], Loss: 0.2704\n",
            "Epoch [31/10], Step [300/469], Loss: 0.1997\n",
            "Epoch [31/10], Step [400/469], Loss: 0.2003\n",
            "Epoch [32/10], Step [100/469], Loss: 0.2960\n",
            "Epoch [32/10], Step [200/469], Loss: 0.1859\n",
            "Epoch [32/10], Step [300/469], Loss: 0.2877\n",
            "Epoch [32/10], Step [400/469], Loss: 0.2418\n",
            "Epoch [33/10], Step [100/469], Loss: 0.3715\n",
            "Epoch [33/10], Step [200/469], Loss: 0.3350\n",
            "Epoch [33/10], Step [300/469], Loss: 0.1714\n",
            "Epoch [33/10], Step [400/469], Loss: 0.2358\n",
            "Epoch [34/10], Step [100/469], Loss: 0.2136\n",
            "Epoch [34/10], Step [200/469], Loss: 0.2106\n",
            "Epoch [34/10], Step [300/469], Loss: 0.3251\n",
            "Epoch [34/10], Step [400/469], Loss: 0.2669\n",
            "Epoch [35/10], Step [100/469], Loss: 0.3005\n",
            "Epoch [35/10], Step [200/469], Loss: 0.2812\n",
            "Epoch [35/10], Step [300/469], Loss: 0.3346\n",
            "Epoch [35/10], Step [400/469], Loss: 0.1822\n",
            "Epoch [36/10], Step [100/469], Loss: 0.3648\n",
            "Epoch [36/10], Step [200/469], Loss: 0.1801\n",
            "Epoch [36/10], Step [300/469], Loss: 0.1686\n",
            "Epoch [36/10], Step [400/469], Loss: 0.1712\n",
            "Epoch [37/10], Step [100/469], Loss: 0.1737\n",
            "Epoch [37/10], Step [200/469], Loss: 0.2244\n",
            "Epoch [37/10], Step [300/469], Loss: 0.1846\n",
            "Epoch [37/10], Step [400/469], Loss: 0.3248\n",
            "Epoch [38/10], Step [100/469], Loss: 0.2333\n",
            "Epoch [38/10], Step [200/469], Loss: 0.3328\n",
            "Epoch [38/10], Step [300/469], Loss: 0.3131\n",
            "Epoch [38/10], Step [400/469], Loss: 0.2681\n",
            "Epoch [39/10], Step [100/469], Loss: 0.3800\n",
            "Epoch [39/10], Step [200/469], Loss: 0.2856\n",
            "Epoch [39/10], Step [300/469], Loss: 0.3249\n",
            "Epoch [39/10], Step [400/469], Loss: 0.1990\n",
            "Epoch [40/10], Step [100/469], Loss: 0.2115\n",
            "Epoch [40/10], Step [200/469], Loss: 0.2517\n",
            "Epoch [40/10], Step [300/469], Loss: 0.2025\n",
            "Epoch [40/10], Step [400/469], Loss: 0.2595\n",
            "Epoch [41/10], Step [100/469], Loss: 0.1709\n",
            "Epoch [41/10], Step [200/469], Loss: 0.2535\n",
            "Epoch [41/10], Step [300/469], Loss: 0.1923\n",
            "Epoch [41/10], Step [400/469], Loss: 0.1668\n",
            "Epoch [42/10], Step [100/469], Loss: 0.1863\n",
            "Epoch [42/10], Step [200/469], Loss: 0.4918\n",
            "Epoch [42/10], Step [300/469], Loss: 0.1264\n",
            "Epoch [42/10], Step [400/469], Loss: 0.2918\n",
            "Epoch [43/10], Step [100/469], Loss: 0.1652\n",
            "Epoch [43/10], Step [200/469], Loss: 0.2061\n",
            "Epoch [43/10], Step [300/469], Loss: 0.2250\n",
            "Epoch [43/10], Step [400/469], Loss: 0.1703\n",
            "Epoch [44/10], Step [100/469], Loss: 0.3202\n",
            "Epoch [44/10], Step [200/469], Loss: 0.3159\n",
            "Epoch [44/10], Step [300/469], Loss: 0.2458\n",
            "Epoch [44/10], Step [400/469], Loss: 0.1573\n",
            "Epoch [45/10], Step [100/469], Loss: 0.2534\n",
            "Epoch [45/10], Step [200/469], Loss: 0.2248\n",
            "Epoch [45/10], Step [300/469], Loss: 0.3168\n",
            "Epoch [45/10], Step [400/469], Loss: 0.2316\n",
            "Epoch [46/10], Step [100/469], Loss: 0.2249\n",
            "Epoch [46/10], Step [200/469], Loss: 0.3963\n",
            "Epoch [46/10], Step [300/469], Loss: 0.2746\n",
            "Epoch [46/10], Step [400/469], Loss: 0.2271\n",
            "Epoch [47/10], Step [100/469], Loss: 0.2288\n",
            "Epoch [47/10], Step [200/469], Loss: 0.4141\n",
            "Epoch [47/10], Step [300/469], Loss: 0.2238\n",
            "Epoch [47/10], Step [400/469], Loss: 0.4670\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [48/10], Step [100/469], Loss: 0.1669\n",
            "Epoch [48/10], Step [200/469], Loss: 0.2529\n",
            "Epoch [48/10], Step [300/469], Loss: 0.2472\n",
            "Epoch [48/10], Step [400/469], Loss: 0.1956\n",
            "Epoch [49/10], Step [100/469], Loss: 0.2821\n",
            "Epoch [49/10], Step [200/469], Loss: 0.2619\n",
            "Epoch [49/10], Step [300/469], Loss: 0.1935\n",
            "Epoch [49/10], Step [400/469], Loss: 0.2564\n",
            "Epoch [50/10], Step [100/469], Loss: 0.2092\n",
            "Epoch [50/10], Step [200/469], Loss: 0.3197\n",
            "Epoch [50/10], Step [300/469], Loss: 0.2903\n",
            "Epoch [50/10], Step [400/469], Loss: 0.0786\n"
          ]
        }
      ],
      "source": [
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(50):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        \n",
        "#         print (images.shape)\n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True \n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAcQl_D6driG"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq_utbdudriG",
        "outputId": "02dd1297-bc51-434b-f904-096a87c655ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92.2 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SWcqgRZdriG"
      },
      "source": [
        "### New model: MLP (multi-layer-perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ISaMj57driH"
      },
      "source": [
        "Previous model used multinomial logistic regression (one linear layer)\\\n",
        "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1Dl_kfQdriH"
      },
      "outputs": [],
      "source": [
        "# New model with multi layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmLoKDmldriH",
        "outputId": "e2e1ea61-82d5-48ef-deb9-b1c87ac83afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 2.2964\n",
            "Epoch [1/10], Step [200/469], Loss: 1.8926\n",
            "Epoch [1/10], Step [300/469], Loss: 1.1192\n",
            "Epoch [1/10], Step [400/469], Loss: 0.7536\n",
            "Epoch [2/10], Step [100/469], Loss: 0.5113\n",
            "Epoch [2/10], Step [200/469], Loss: 0.6191\n",
            "Epoch [2/10], Step [300/469], Loss: 0.4783\n",
            "Epoch [2/10], Step [400/469], Loss: 0.3960\n",
            "Epoch [3/10], Step [100/469], Loss: 0.4134\n",
            "Epoch [3/10], Step [200/469], Loss: 0.3941\n",
            "Epoch [3/10], Step [300/469], Loss: 0.4233\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2516\n",
            "Epoch [4/10], Step [100/469], Loss: 0.2465\n",
            "Epoch [4/10], Step [200/469], Loss: 0.3333\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2859\n",
            "Epoch [4/10], Step [400/469], Loss: 0.3381\n",
            "Epoch [5/10], Step [100/469], Loss: 0.1660\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2062\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1298\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2145\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2352\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2277\n",
            "Epoch [6/10], Step [300/469], Loss: 0.1186\n",
            "Epoch [6/10], Step [400/469], Loss: 0.1727\n",
            "Epoch [7/10], Step [100/469], Loss: 0.1955\n",
            "Epoch [7/10], Step [200/469], Loss: 0.3106\n",
            "Epoch [7/10], Step [300/469], Loss: 0.2667\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2342\n",
            "Epoch [8/10], Step [100/469], Loss: 0.1082\n",
            "Epoch [8/10], Step [200/469], Loss: 0.2122\n",
            "Epoch [8/10], Step [300/469], Loss: 0.2486\n",
            "Epoch [8/10], Step [400/469], Loss: 0.1468\n",
            "Epoch [9/10], Step [100/469], Loss: 0.0860\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0969\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1529\n",
            "Epoch [9/10], Step [400/469], Loss: 0.1331\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1245\n",
            "Epoch [10/10], Step [200/469], Loss: 0.2092\n",
            "Epoch [10/10], Step [300/469], Loss: 0.1173\n",
            "Epoch [10/10], Step [400/469], Loss: 0.1904\n"
          ]
        }
      ],
      "source": [
        "# Generate model\n",
        "model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n",
        "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
        "\n",
        "# Upload model to GPU\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True \n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKK_VlZhdriH",
        "outputId": "0c300e13-d0de-4f03-c35d-333de0c0a032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 95.09 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5lbMobbdriH"
      },
      "source": [
        "### Change the following options to obtain better accuracy!! (try it by your-self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e8RXOoSdriH"
      },
      "source": [
        "#### (1) Model configurations: \n",
        "- size of hidden layer units\n",
        "- number of layers\n",
        "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
        "\n",
        "#### (2) Optimization configurations\n",
        "- learning rate\n",
        "- epoch\n",
        "- type of optimizer\n",
        "- momentem hyperparameter"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "ai504_03_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Efs0kibDdriB",
        "reMTMllQdriC",
        "xkwXRPbidriD",
        "MX82GfH1driE",
        "Pn1NemM-driE",
        "uJorJLHzdriF",
        "gQmbIv1ZdriF",
        "hVQty5XzdriF",
        "ynbiBVtNdriG",
        "QAcQl_D6driG",
        "5SWcqgRZdriG",
        "u5lbMobbdriH",
        "-e8RXOoSdriH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82ce801b0f414818a2bca4d7afb9732e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05dd84e745284ea184c841d4cb30a007",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6abe08b0c96b408baa62e48069072a3b",
              "IPY_MODEL_9ce60f3174c54ea08bfb0be822532d17",
              "IPY_MODEL_84934e21775b46f4a37a6eb13b3b0c0a"
            ]
          }
        },
        "05dd84e745284ea184c841d4cb30a007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6abe08b0c96b408baa62e48069072a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d3f358622934f85a1f65898b647a15d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_685437017e68411c8ba0661eefcd4d1a"
          }
        },
        "9ce60f3174c54ea08bfb0be822532d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ce6a72099b743219d98808fcb12410f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77dbcb05a88e4e9bae01cf2ef6470fad"
          }
        },
        "84934e21775b46f4a37a6eb13b3b0c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_039f1deb71dc4c1f98213adef7b49bb6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 21328669.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f6212f64f5c47859002e0783b7b03b6"
          }
        },
        "1d3f358622934f85a1f65898b647a15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "685437017e68411c8ba0661eefcd4d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ce6a72099b743219d98808fcb12410f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77dbcb05a88e4e9bae01cf2ef6470fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "039f1deb71dc4c1f98213adef7b49bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f6212f64f5c47859002e0783b7b03b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae72f88799da41eaa1da11c235a44e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5f7b1a04bda84030b964ce1c7bf7550d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_defb7a8bf92f47709fb1a9607e7c0139",
              "IPY_MODEL_05c4875a4cab4826bf0d42acdda53bd6",
              "IPY_MODEL_016fa05d5c414eb4b27df99b3da01329"
            ]
          }
        },
        "5f7b1a04bda84030b964ce1c7bf7550d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "defb7a8bf92f47709fb1a9607e7c0139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ed4bb406d7e4a5195d5fcaec2b63316",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d192558e10bb49d68627ca9d11d68fd9"
          }
        },
        "05c4875a4cab4826bf0d42acdda53bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c52afe9ae4f14608b6a2931c501ad571",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a90f23e044384b4ca68765d24098b2e9"
          }
        },
        "016fa05d5c414eb4b27df99b3da01329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f98ac5d3eb624ee9a7ebc46a45aba889",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 788481.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb677429e6b149a3a059b5d084ef818a"
          }
        },
        "9ed4bb406d7e4a5195d5fcaec2b63316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d192558e10bb49d68627ca9d11d68fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c52afe9ae4f14608b6a2931c501ad571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a90f23e044384b4ca68765d24098b2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f98ac5d3eb624ee9a7ebc46a45aba889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb677429e6b149a3a059b5d084ef818a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d2469f2b243420b97cba7712127992e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71321d6189bd4572a64ff50443f5dee4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d51bf9fdde24aac87ac7194f14a4a8b",
              "IPY_MODEL_a5a9dda8ba4440e4bec13a033013a95a",
              "IPY_MODEL_dd1028be15d34724b90c19404cc03258"
            ]
          }
        },
        "71321d6189bd4572a64ff50443f5dee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d51bf9fdde24aac87ac7194f14a4a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1df58c78c6a4f168668c2ab617308ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2dcaaaac664435cb1c26b9903876d8b"
          }
        },
        "a5a9dda8ba4440e4bec13a033013a95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d612224dd87475f9d2a94fa19d386bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4208e9b71e1e444da1a1afecd82af5bf"
          }
        },
        "dd1028be15d34724b90c19404cc03258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c1f0aed54f74da0ab0f15dd7a4e0624",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 19020997.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78720c06dba4447286ced65295ce0dc1"
          }
        },
        "d1df58c78c6a4f168668c2ab617308ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2dcaaaac664435cb1c26b9903876d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d612224dd87475f9d2a94fa19d386bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4208e9b71e1e444da1a1afecd82af5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c1f0aed54f74da0ab0f15dd7a4e0624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78720c06dba4447286ced65295ce0dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e664dea983249ac952444aadcf6f619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a6f267706c5477d9c3f5d244dc3cd75",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc21eaefc907404db8af22af89d1b21d",
              "IPY_MODEL_c0f03843f92c4bbbb194eb37efded800",
              "IPY_MODEL_2b20154ce71445ab9fa99cd73b0e36fd"
            ]
          }
        },
        "0a6f267706c5477d9c3f5d244dc3cd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc21eaefc907404db8af22af89d1b21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a9882d6f35a4547b8461005bf793fac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40715c1505914e7a9ebaf57dd56a71b0"
          }
        },
        "c0f03843f92c4bbbb194eb37efded800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_067d6c9293f5449799d52a4b4583bb4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5cdb3b11c514e49ad0bda92e1fea09a"
          }
        },
        "2b20154ce71445ab9fa99cd73b0e36fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dda412cfec8349af90f21e543daa9dcf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 140301.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af3dd60447a74fa3a25770e6e298fe74"
          }
        },
        "6a9882d6f35a4547b8461005bf793fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40715c1505914e7a9ebaf57dd56a71b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "067d6c9293f5449799d52a4b4583bb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5cdb3b11c514e49ad0bda92e1fea09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dda412cfec8349af90f21e543daa9dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af3dd60447a74fa3a25770e6e298fe74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}